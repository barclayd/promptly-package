---
title: AI SDK Integration
description: Use aiParams() to spread prompt configuration directly into Vercel AI SDK functions.
---

import { Aside } from '@astrojs/starlight/components';

The `aiParams()` method is designed as the natural companion for developers using the [Vercel AI SDK](https://sdk.vercel.ai). It returns an object you can spread directly into `generateText()`, `streamText()`, and other AI SDK functions.

## Basic usage

```typescript
import { createPromptlyClient } from '@promptlycms/prompts';
import { generateText } from 'ai';

const promptly = createPromptlyClient();

const params = await promptly.aiParams('my-prompt', {
  variables: { name: 'Alice', task: 'code review' },
});

const { text } = await generateText({
  ...params,
});
```

## What `aiParams()` returns

The returned object includes everything the AI SDK needs:

```typescript
const params = await promptly.aiParams('my-prompt', {
  variables: { name: 'Alice' },
});

// params contains:
// {
//   system: 'You are a helpful assistant...',
//   prompt: 'Hello Alice, how can I help?',
//   temperature: 0.7,
//   model: LanguageModel,        // auto-resolved from CMS config
//   output?: Output.object(...)  // if CMS schema is defined
// }
```

- **`system`** — the system message from the CMS
- **`prompt`** — the user message with variables interpolated
- **`temperature`** — the temperature setting from the CMS
- **`model`** — automatically resolved from the model configured in the CMS (see [Model Resolution](/guides/model-resolution/))
- **`output`** — automatically populated with a Zod schema wrapped in `Output.object()` if the prompt has a structured output schema defined in the CMS (see [Structured Output](/guides/structured-output/))

## With `generateText()`

```typescript
import { generateText } from 'ai';

const { text } = await generateText({
  ...await promptly.aiParams('summarize', {
    variables: { content: articleText },
  }),
});
```

## With `streamText()`

```typescript
import { streamText } from 'ai';

const stream = streamText({
  ...await promptly.aiParams('chat-assistant', {
    variables: { context: conversationHistory },
  }),
});

for await (const chunk of stream.textStream) {
  process.stdout.write(chunk);
}
```

## Version pinning

Fetch a specific prompt version:

```typescript
const params = await promptly.aiParams('my-prompt', {
  version: '2.0.0',
  variables: { name: 'Alice' },
});
```

## Structured output

If your prompt has a structured output schema defined in the CMS, `aiParams()` automatically includes the `output` property:

```typescript
const params = await promptly.aiParams('extract-data');

// params.output is automatically populated with Output.object({ schema })
const { object } = await generateObject({
  ...params,
});

// object is typed according to your CMS schema
```

See the [Structured Output](/guides/structured-output/) guide for details.

## When to use `aiParams()` vs `getPrompt()`

| Use case | Method |
|----------|--------|
| Simple AI SDK integration | `aiParams()` |
| Need fine-grained message control | `getPrompt()` |
| Provider-specific options (e.g. cache control) | `getPrompt()` |
| Custom messages array | `getPrompt()` |
| Spread-and-go simplicity | `aiParams()` |

<Aside type="tip">
  Use `aiParams()` when you want the simplest path from CMS to AI generation. Use `getPrompt()` when you need more control over the messages array or provider-specific options.
</Aside>

## Next steps

- Learn how [model resolution](/guides/model-resolution/) works
- See [structured output](/guides/structured-output/) for Zod schemas from the CMS
- View the full [client API reference](/reference/client-api/)
