---
title: 'PromptlyCMS'
description: Type-safe prompts for AI applications made delightfully simple.
template: splash
hero:
  tagline: Type-safe prompts for AI applications made delightfully simple.
  actions:
    - text: Get Started
      link: /getting-started/installation/
      icon: right-arrow
      variant: primary
    - text: View on GitHub
      link: https://github.com/barclayd/promptly-package
      icon: external
      variant: minimal
---

import { Card, CardGrid, Tabs, TabItem } from '@astrojs/starlight/components';

## Install

<Tabs>
  <TabItem label="bun">
    ```bash
    bun add @promptlycms/prompts
    ```
  </TabItem>
  <TabItem label="npm">
    ```bash
    npm install @promptlycms/prompts
    ```
  </TabItem>
  <TabItem label="yarn">
    ```bash
    yarn add @promptlycms/prompts
    ```
  </TabItem>
  <TabItem label="pnpm">
    ```bash
    pnpm add @promptlycms/prompts
    ```
  </TabItem>
</Tabs>

## Features

<CardGrid>
  <Card title="Runtime Client" icon="rocket">
    Fetch prompts with `getPrompt()` and `getPrompts()`. Typed template variables with autocomplete when you run codegen.
  </Card>
  <Card title="AI SDK Integration" icon="puzzle">
    `aiParams()` returns spread-ready params for [Vercel AI SDK](https://sdk.vercel.ai) functions like `generateText()` and `streamText()`.
  </Card>
  <Card title="Multi-Model Auto-Detection" icon="setting">
    Automatically resolves Anthropic, OpenAI, Google, and Mistral models from your CMS config. No manual provider setup.
  </Card>
  <Card title="Codegen for Type Safety" icon="seti:typescript">
    Run `npx promptly generate` to generate typed template variables via declaration merging. Full autocomplete in your editor.
  </Card>
</CardGrid>

## Get started in 3 steps

```typescript
import { createPromptlyClient } from '@promptlycms/prompts';
import { generateText } from 'ai';

const { getPrompt } = createPromptlyClient();

// promptly was created to be as compatible with Vercel's ai sdk package as possible
const { userMessage, systemMessage, temperature, model } = await getPrompt(
  'upsellMessage',
);

const { text } = await generateText({
  model,
  messages: [
    {
      role: 'system',
      content: systemMessage,
    },
    {
      role: 'user',
      content: userMessage({
        username,
        persuasionLevel: 1,
        recentPurchases,
      }),
    },
  ],
  temperature,
});

// your AI agent output as usual with 0 prompts hardcoded in your codebase
console.log(text);
```
